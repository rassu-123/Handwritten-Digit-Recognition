{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Handwritten digits identifier.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "T8zX7gsowB3s"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torchvision.datasets import MNIST\n",
        "import matplotlib.pyplot as plt\n",
        "import torchvision.transforms as transforms\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "%matplotlib inline"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCMLbxrEwk2O"
      },
      "source": [
        "dataset = MNIST(root='data/', download=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z3hCsaRFxMvQ"
      },
      "source": [
        "# MNIST dataset (images and labels)\n",
        "dataset = MNIST(root='data/', \n",
        "                train=True,\n",
        "                transform=transforms.ToTensor())"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ymH4xmYCx2Rs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b24fd68-953b-4d36-d228-d1e9a4ba668d"
      },
      "source": [
        "len(dataset)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVOW9Qjvx50T",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "234c6dec-b58b-4827-f63c-a8f7fc97bb88"
      },
      "source": [
        "test_dataset = MNIST(root='data/', train=False)\n",
        "len(test_dataset)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yxvyZ73xgL5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed2b9d14-bab2-4120-b76d-914704111de4"
      },
      "source": [
        "from torch.utils.data import random_split\n",
        "\n",
        "train_ds, val_ds = random_split(dataset, [50000, 10000])\n",
        "len(train_ds), len(val_ds)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(50000, 10000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M5EdRM1pycgn"
      },
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "batch_size = 128\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size, shuffle=True)\n",
        "val_loader = DataLoader(val_ds, batch_size)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzSZW1p0yhng"
      },
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "input_size = 28*28\n",
        "num_classes = 10\n",
        "\n",
        "# Logistic regression model\n",
        "model = nn.Linear(input_size, num_classes)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QLraA5xryqvQ",
        "outputId": "df918758-ad1c-4aeb-8d7c-8a62bc04cdff"
      },
      "source": [
        "for images, labels in train_loader:\n",
        "  break\n",
        "images.reshape(128, 784).shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 784])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YfZBx8LE10hf"
      },
      "source": [
        "def accuracy(outputs, labels):\n",
        "    _, preds = torch.max(outputs, dim=1)\n",
        "    return torch.tensor(torch.sum(preds == labels).item() / len(preds))"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E1QhGYBV0_JG"
      },
      "source": [
        "def evaluate(model, val_loader):\n",
        "    outputs = [model.validation_step(batch) for batch in val_loader]\n",
        "    return model.validation_epoch_end(outputs)"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I5vuMKV3zwh9"
      },
      "source": [
        "class MnistModel(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.linear = nn.Linear(input_size, num_classes)\n",
        "        \n",
        "    def forward(self, xb):\n",
        "        xb = xb.reshape(-1, 784)\n",
        "        out = self.linear(xb)\n",
        "        return out\n",
        "    \n",
        "    def training_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                  # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels) # Calculate loss\n",
        "        return loss\n",
        "    \n",
        "    def validation_step(self, batch):\n",
        "        images, labels = batch \n",
        "        out = self(images)                    # Generate predictions\n",
        "        loss = F.cross_entropy(out, labels)   # Calculate loss\n",
        "        acc = accuracy(out, labels)           # Calculate accuracy\n",
        "        return {'val_loss': loss, 'val_acc': acc}\n",
        "        \n",
        "    def validation_epoch_end(self, outputs):\n",
        "        batch_losses = [x['val_loss'] for x in outputs]\n",
        "        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n",
        "        batch_accs = [x['val_acc'] for x in outputs]\n",
        "        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n",
        "        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n",
        "    \n",
        "    def epoch_end(self, epoch, result):\n",
        "        print(\"Epoch [{}], val_loss: {:.4f}, val_acc: {:.4f}\".format(epoch, result['val_loss'], result['val_acc']))\n",
        "    \n",
        "model = MnistModel()"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3F2sDBJa0w2X"
      },
      "source": [
        "def fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n",
        "    optimizer = opt_func(model.parameters(), lr)\n",
        "    history = [] # for recording epoch-wise results\n",
        "    \n",
        "    for epoch in range(epochs):\n",
        "        \n",
        "        # Training Phase \n",
        "        for batch in train_loader:\n",
        "            loss = model.training_step(batch)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "        \n",
        "        # Validation phase\n",
        "        result = evaluate(model, val_loader)\n",
        "        model.epoch_end(epoch, result)\n",
        "        history.append(result)\n",
        "\n",
        "    return history"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oLWNog8V05Rz",
        "outputId": "7c2c16a2-896c-456d-d6c6-c0179c9dfe86"
      },
      "source": [
        "history1 = fit(5, 0.001, model, train_loader, val_loader)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 2.0017, val_acc: 0.5744\n",
            "Epoch [1], val_loss: 1.7210, val_acc: 0.7182\n",
            "Epoch [2], val_loss: 1.5108, val_acc: 0.7563\n",
            "Epoch [3], val_loss: 1.3522, val_acc: 0.7795\n",
            "Epoch [4], val_loss: 1.2306, val_acc: 0.7941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "buGFg-QQ2K0O",
        "outputId": "c5932dce-3f80-4670-e1d2-5d7980cb3cb7"
      },
      "source": [
        "history2 = fit(5, 0.001, model, train_loader, val_loader)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 1.1354, val_acc: 0.8035\n",
            "Epoch [1], val_loss: 1.0593, val_acc: 0.8106\n",
            "Epoch [2], val_loss: 0.9972, val_acc: 0.8152\n",
            "Epoch [3], val_loss: 0.9457, val_acc: 0.8193\n",
            "Epoch [4], val_loss: 0.9022, val_acc: 0.8237\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BnZjB7dn2PeX",
        "outputId": "dca7b5bd-616f-444d-93cb-226226f6f3be"
      },
      "source": [
        "history3 = fit(5, 0.001, model, train_loader, val_loader)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 0.8651, val_acc: 0.8279\n",
            "Epoch [1], val_loss: 0.8329, val_acc: 0.8314\n",
            "Epoch [2], val_loss: 0.8048, val_acc: 0.8342\n",
            "Epoch [3], val_loss: 0.7800, val_acc: 0.8384\n",
            "Epoch [4], val_loss: 0.7579, val_acc: 0.8412\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_-gSu-v2W1c",
        "outputId": "7a957f36-d90f-494c-ee6f-cfd7bea84cc3"
      },
      "source": [
        "history3 = fit(200, 0.001, model, train_loader, val_loader)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 0.7381, val_acc: 0.8429\n",
            "Epoch [1], val_loss: 0.7203, val_acc: 0.8448\n",
            "Epoch [2], val_loss: 0.7041, val_acc: 0.8480\n",
            "Epoch [3], val_loss: 0.6894, val_acc: 0.8496\n",
            "Epoch [4], val_loss: 0.6759, val_acc: 0.8512\n",
            "Epoch [5], val_loss: 0.6634, val_acc: 0.8531\n",
            "Epoch [6], val_loss: 0.6519, val_acc: 0.8544\n",
            "Epoch [7], val_loss: 0.6413, val_acc: 0.8554\n",
            "Epoch [8], val_loss: 0.6314, val_acc: 0.8562\n",
            "Epoch [9], val_loss: 0.6221, val_acc: 0.8570\n",
            "Epoch [10], val_loss: 0.6135, val_acc: 0.8583\n",
            "Epoch [11], val_loss: 0.6054, val_acc: 0.8595\n",
            "Epoch [12], val_loss: 0.5978, val_acc: 0.8607\n",
            "Epoch [13], val_loss: 0.5906, val_acc: 0.8617\n",
            "Epoch [14], val_loss: 0.5838, val_acc: 0.8624\n",
            "Epoch [15], val_loss: 0.5774, val_acc: 0.8627\n",
            "Epoch [16], val_loss: 0.5713, val_acc: 0.8630\n",
            "Epoch [17], val_loss: 0.5656, val_acc: 0.8636\n",
            "Epoch [18], val_loss: 0.5601, val_acc: 0.8647\n",
            "Epoch [19], val_loss: 0.5549, val_acc: 0.8656\n",
            "Epoch [20], val_loss: 0.5499, val_acc: 0.8660\n",
            "Epoch [21], val_loss: 0.5451, val_acc: 0.8673\n",
            "Epoch [22], val_loss: 0.5406, val_acc: 0.8679\n",
            "Epoch [23], val_loss: 0.5362, val_acc: 0.8695\n",
            "Epoch [24], val_loss: 0.5321, val_acc: 0.8702\n",
            "Epoch [25], val_loss: 0.5281, val_acc: 0.8711\n",
            "Epoch [26], val_loss: 0.5242, val_acc: 0.8711\n",
            "Epoch [27], val_loss: 0.5205, val_acc: 0.8713\n",
            "Epoch [28], val_loss: 0.5170, val_acc: 0.8717\n",
            "Epoch [29], val_loss: 0.5135, val_acc: 0.8722\n",
            "Epoch [30], val_loss: 0.5102, val_acc: 0.8724\n",
            "Epoch [31], val_loss: 0.5071, val_acc: 0.8727\n",
            "Epoch [32], val_loss: 0.5039, val_acc: 0.8734\n",
            "Epoch [33], val_loss: 0.5010, val_acc: 0.8737\n",
            "Epoch [34], val_loss: 0.4981, val_acc: 0.8741\n",
            "Epoch [35], val_loss: 0.4953, val_acc: 0.8748\n",
            "Epoch [36], val_loss: 0.4926, val_acc: 0.8753\n",
            "Epoch [37], val_loss: 0.4900, val_acc: 0.8754\n",
            "Epoch [38], val_loss: 0.4875, val_acc: 0.8760\n",
            "Epoch [39], val_loss: 0.4850, val_acc: 0.8760\n",
            "Epoch [40], val_loss: 0.4826, val_acc: 0.8763\n",
            "Epoch [41], val_loss: 0.4804, val_acc: 0.8763\n",
            "Epoch [42], val_loss: 0.4781, val_acc: 0.8767\n",
            "Epoch [43], val_loss: 0.4759, val_acc: 0.8769\n",
            "Epoch [44], val_loss: 0.4738, val_acc: 0.8771\n",
            "Epoch [45], val_loss: 0.4717, val_acc: 0.8774\n",
            "Epoch [46], val_loss: 0.4697, val_acc: 0.8775\n",
            "Epoch [47], val_loss: 0.4677, val_acc: 0.8776\n",
            "Epoch [48], val_loss: 0.4658, val_acc: 0.8781\n",
            "Epoch [49], val_loss: 0.4639, val_acc: 0.8783\n",
            "Epoch [50], val_loss: 0.4621, val_acc: 0.8785\n",
            "Epoch [51], val_loss: 0.4603, val_acc: 0.8791\n",
            "Epoch [52], val_loss: 0.4586, val_acc: 0.8791\n",
            "Epoch [53], val_loss: 0.4569, val_acc: 0.8800\n",
            "Epoch [54], val_loss: 0.4553, val_acc: 0.8802\n",
            "Epoch [55], val_loss: 0.4537, val_acc: 0.8804\n",
            "Epoch [56], val_loss: 0.4520, val_acc: 0.8808\n",
            "Epoch [57], val_loss: 0.4505, val_acc: 0.8811\n",
            "Epoch [58], val_loss: 0.4490, val_acc: 0.8815\n",
            "Epoch [59], val_loss: 0.4475, val_acc: 0.8817\n",
            "Epoch [60], val_loss: 0.4461, val_acc: 0.8822\n",
            "Epoch [61], val_loss: 0.4447, val_acc: 0.8825\n",
            "Epoch [62], val_loss: 0.4433, val_acc: 0.8824\n",
            "Epoch [63], val_loss: 0.4419, val_acc: 0.8827\n",
            "Epoch [64], val_loss: 0.4406, val_acc: 0.8831\n",
            "Epoch [65], val_loss: 0.4393, val_acc: 0.8834\n",
            "Epoch [66], val_loss: 0.4380, val_acc: 0.8835\n",
            "Epoch [67], val_loss: 0.4368, val_acc: 0.8839\n",
            "Epoch [68], val_loss: 0.4356, val_acc: 0.8840\n",
            "Epoch [69], val_loss: 0.4344, val_acc: 0.8841\n",
            "Epoch [70], val_loss: 0.4332, val_acc: 0.8844\n",
            "Epoch [71], val_loss: 0.4320, val_acc: 0.8845\n",
            "Epoch [72], val_loss: 0.4309, val_acc: 0.8850\n",
            "Epoch [73], val_loss: 0.4297, val_acc: 0.8851\n",
            "Epoch [74], val_loss: 0.4286, val_acc: 0.8853\n",
            "Epoch [75], val_loss: 0.4275, val_acc: 0.8862\n",
            "Epoch [76], val_loss: 0.4265, val_acc: 0.8862\n",
            "Epoch [77], val_loss: 0.4254, val_acc: 0.8863\n",
            "Epoch [78], val_loss: 0.4244, val_acc: 0.8864\n",
            "Epoch [79], val_loss: 0.4234, val_acc: 0.8866\n",
            "Epoch [80], val_loss: 0.4224, val_acc: 0.8870\n",
            "Epoch [81], val_loss: 0.4215, val_acc: 0.8871\n",
            "Epoch [82], val_loss: 0.4205, val_acc: 0.8874\n",
            "Epoch [83], val_loss: 0.4195, val_acc: 0.8876\n",
            "Epoch [84], val_loss: 0.4186, val_acc: 0.8879\n",
            "Epoch [85], val_loss: 0.4177, val_acc: 0.8879\n",
            "Epoch [86], val_loss: 0.4168, val_acc: 0.8883\n",
            "Epoch [87], val_loss: 0.4159, val_acc: 0.8884\n",
            "Epoch [88], val_loss: 0.4151, val_acc: 0.8885\n",
            "Epoch [89], val_loss: 0.4142, val_acc: 0.8885\n",
            "Epoch [90], val_loss: 0.4133, val_acc: 0.8891\n",
            "Epoch [91], val_loss: 0.4125, val_acc: 0.8891\n",
            "Epoch [92], val_loss: 0.4117, val_acc: 0.8892\n",
            "Epoch [93], val_loss: 0.4109, val_acc: 0.8895\n",
            "Epoch [94], val_loss: 0.4101, val_acc: 0.8896\n",
            "Epoch [95], val_loss: 0.4093, val_acc: 0.8899\n",
            "Epoch [96], val_loss: 0.4085, val_acc: 0.8899\n",
            "Epoch [97], val_loss: 0.4078, val_acc: 0.8902\n",
            "Epoch [98], val_loss: 0.4070, val_acc: 0.8903\n",
            "Epoch [99], val_loss: 0.4063, val_acc: 0.8906\n",
            "Epoch [100], val_loss: 0.4055, val_acc: 0.8910\n",
            "Epoch [101], val_loss: 0.4048, val_acc: 0.8914\n",
            "Epoch [102], val_loss: 0.4041, val_acc: 0.8915\n",
            "Epoch [103], val_loss: 0.4034, val_acc: 0.8917\n",
            "Epoch [104], val_loss: 0.4027, val_acc: 0.8918\n",
            "Epoch [105], val_loss: 0.4020, val_acc: 0.8919\n",
            "Epoch [106], val_loss: 0.4013, val_acc: 0.8923\n",
            "Epoch [107], val_loss: 0.4007, val_acc: 0.8927\n",
            "Epoch [108], val_loss: 0.4000, val_acc: 0.8927\n",
            "Epoch [109], val_loss: 0.3994, val_acc: 0.8928\n",
            "Epoch [110], val_loss: 0.3987, val_acc: 0.8929\n",
            "Epoch [111], val_loss: 0.3981, val_acc: 0.8932\n",
            "Epoch [112], val_loss: 0.3975, val_acc: 0.8933\n",
            "Epoch [113], val_loss: 0.3969, val_acc: 0.8932\n",
            "Epoch [114], val_loss: 0.3962, val_acc: 0.8932\n",
            "Epoch [115], val_loss: 0.3956, val_acc: 0.8934\n",
            "Epoch [116], val_loss: 0.3950, val_acc: 0.8936\n",
            "Epoch [117], val_loss: 0.3944, val_acc: 0.8937\n",
            "Epoch [118], val_loss: 0.3939, val_acc: 0.8938\n",
            "Epoch [119], val_loss: 0.3933, val_acc: 0.8940\n",
            "Epoch [120], val_loss: 0.3927, val_acc: 0.8942\n",
            "Epoch [121], val_loss: 0.3922, val_acc: 0.8943\n",
            "Epoch [122], val_loss: 0.3916, val_acc: 0.8945\n",
            "Epoch [123], val_loss: 0.3910, val_acc: 0.8944\n",
            "Epoch [124], val_loss: 0.3905, val_acc: 0.8942\n",
            "Epoch [125], val_loss: 0.3900, val_acc: 0.8945\n",
            "Epoch [126], val_loss: 0.3894, val_acc: 0.8946\n",
            "Epoch [127], val_loss: 0.3889, val_acc: 0.8946\n",
            "Epoch [128], val_loss: 0.3884, val_acc: 0.8949\n",
            "Epoch [129], val_loss: 0.3879, val_acc: 0.8950\n",
            "Epoch [130], val_loss: 0.3874, val_acc: 0.8951\n",
            "Epoch [131], val_loss: 0.3869, val_acc: 0.8953\n",
            "Epoch [132], val_loss: 0.3864, val_acc: 0.8955\n",
            "Epoch [133], val_loss: 0.3859, val_acc: 0.8958\n",
            "Epoch [134], val_loss: 0.3854, val_acc: 0.8958\n",
            "Epoch [135], val_loss: 0.3849, val_acc: 0.8959\n",
            "Epoch [136], val_loss: 0.3844, val_acc: 0.8960\n",
            "Epoch [137], val_loss: 0.3840, val_acc: 0.8960\n",
            "Epoch [138], val_loss: 0.3835, val_acc: 0.8962\n",
            "Epoch [139], val_loss: 0.3830, val_acc: 0.8962\n",
            "Epoch [140], val_loss: 0.3826, val_acc: 0.8963\n",
            "Epoch [141], val_loss: 0.3821, val_acc: 0.8964\n",
            "Epoch [142], val_loss: 0.3817, val_acc: 0.8961\n",
            "Epoch [143], val_loss: 0.3812, val_acc: 0.8963\n",
            "Epoch [144], val_loss: 0.3808, val_acc: 0.8965\n",
            "Epoch [145], val_loss: 0.3804, val_acc: 0.8966\n",
            "Epoch [146], val_loss: 0.3799, val_acc: 0.8968\n",
            "Epoch [147], val_loss: 0.3795, val_acc: 0.8969\n",
            "Epoch [148], val_loss: 0.3791, val_acc: 0.8970\n",
            "Epoch [149], val_loss: 0.3786, val_acc: 0.8971\n",
            "Epoch [150], val_loss: 0.3782, val_acc: 0.8973\n",
            "Epoch [151], val_loss: 0.3778, val_acc: 0.8976\n",
            "Epoch [152], val_loss: 0.3774, val_acc: 0.8976\n",
            "Epoch [153], val_loss: 0.3770, val_acc: 0.8977\n",
            "Epoch [154], val_loss: 0.3766, val_acc: 0.8978\n",
            "Epoch [155], val_loss: 0.3762, val_acc: 0.8979\n",
            "Epoch [156], val_loss: 0.3758, val_acc: 0.8981\n",
            "Epoch [157], val_loss: 0.3755, val_acc: 0.8983\n",
            "Epoch [158], val_loss: 0.3751, val_acc: 0.8984\n",
            "Epoch [159], val_loss: 0.3747, val_acc: 0.8985\n",
            "Epoch [160], val_loss: 0.3743, val_acc: 0.8988\n",
            "Epoch [161], val_loss: 0.3739, val_acc: 0.8988\n",
            "Epoch [162], val_loss: 0.3736, val_acc: 0.8987\n",
            "Epoch [163], val_loss: 0.3732, val_acc: 0.8987\n",
            "Epoch [164], val_loss: 0.3728, val_acc: 0.8988\n",
            "Epoch [165], val_loss: 0.3725, val_acc: 0.8990\n",
            "Epoch [166], val_loss: 0.3721, val_acc: 0.8991\n",
            "Epoch [167], val_loss: 0.3717, val_acc: 0.8992\n",
            "Epoch [168], val_loss: 0.3714, val_acc: 0.8993\n",
            "Epoch [169], val_loss: 0.3710, val_acc: 0.8994\n",
            "Epoch [170], val_loss: 0.3707, val_acc: 0.8992\n",
            "Epoch [171], val_loss: 0.3703, val_acc: 0.8994\n",
            "Epoch [172], val_loss: 0.3700, val_acc: 0.8993\n",
            "Epoch [173], val_loss: 0.3697, val_acc: 0.8994\n",
            "Epoch [174], val_loss: 0.3694, val_acc: 0.8994\n",
            "Epoch [175], val_loss: 0.3690, val_acc: 0.8993\n",
            "Epoch [176], val_loss: 0.3687, val_acc: 0.8994\n",
            "Epoch [177], val_loss: 0.3684, val_acc: 0.8994\n",
            "Epoch [178], val_loss: 0.3680, val_acc: 0.8996\n",
            "Epoch [179], val_loss: 0.3677, val_acc: 0.8998\n",
            "Epoch [180], val_loss: 0.3674, val_acc: 0.8998\n",
            "Epoch [181], val_loss: 0.3671, val_acc: 0.8999\n",
            "Epoch [182], val_loss: 0.3668, val_acc: 0.9002\n",
            "Epoch [183], val_loss: 0.3664, val_acc: 0.9001\n",
            "Epoch [184], val_loss: 0.3662, val_acc: 0.9003\n",
            "Epoch [185], val_loss: 0.3658, val_acc: 0.9005\n",
            "Epoch [186], val_loss: 0.3655, val_acc: 0.9007\n",
            "Epoch [187], val_loss: 0.3652, val_acc: 0.9007\n",
            "Epoch [188], val_loss: 0.3649, val_acc: 0.9007\n",
            "Epoch [189], val_loss: 0.3646, val_acc: 0.9008\n",
            "Epoch [190], val_loss: 0.3643, val_acc: 0.9009\n",
            "Epoch [191], val_loss: 0.3640, val_acc: 0.9009\n",
            "Epoch [192], val_loss: 0.3637, val_acc: 0.9012\n",
            "Epoch [193], val_loss: 0.3635, val_acc: 0.9009\n",
            "Epoch [194], val_loss: 0.3632, val_acc: 0.9011\n",
            "Epoch [195], val_loss: 0.3629, val_acc: 0.9011\n",
            "Epoch [196], val_loss: 0.3626, val_acc: 0.9013\n",
            "Epoch [197], val_loss: 0.3623, val_acc: 0.9012\n",
            "Epoch [198], val_loss: 0.3621, val_acc: 0.9014\n",
            "Epoch [199], val_loss: 0.3618, val_acc: 0.9014\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OkC4kpyq9Ait",
        "outputId": "ba4e930b-9502-4e6e-e91c-0a163c764935"
      },
      "source": [
        "history4 = fit(100, 0.001, model, train_loader, val_loader)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch [0], val_loss: 0.3615, val_acc: 0.9015\n",
            "Epoch [1], val_loss: 0.3612, val_acc: 0.9018\n",
            "Epoch [2], val_loss: 0.3609, val_acc: 0.9019\n",
            "Epoch [3], val_loss: 0.3607, val_acc: 0.9018\n",
            "Epoch [4], val_loss: 0.3604, val_acc: 0.9021\n",
            "Epoch [5], val_loss: 0.3602, val_acc: 0.9020\n",
            "Epoch [6], val_loss: 0.3599, val_acc: 0.9020\n",
            "Epoch [7], val_loss: 0.3596, val_acc: 0.9022\n",
            "Epoch [8], val_loss: 0.3594, val_acc: 0.9022\n",
            "Epoch [9], val_loss: 0.3591, val_acc: 0.9022\n",
            "Epoch [10], val_loss: 0.3589, val_acc: 0.9026\n",
            "Epoch [11], val_loss: 0.3586, val_acc: 0.9026\n",
            "Epoch [12], val_loss: 0.3583, val_acc: 0.9029\n",
            "Epoch [13], val_loss: 0.3581, val_acc: 0.9028\n",
            "Epoch [14], val_loss: 0.3579, val_acc: 0.9028\n",
            "Epoch [15], val_loss: 0.3576, val_acc: 0.9028\n",
            "Epoch [16], val_loss: 0.3574, val_acc: 0.9028\n",
            "Epoch [17], val_loss: 0.3571, val_acc: 0.9028\n",
            "Epoch [18], val_loss: 0.3569, val_acc: 0.9030\n",
            "Epoch [19], val_loss: 0.3566, val_acc: 0.9029\n",
            "Epoch [20], val_loss: 0.3564, val_acc: 0.9029\n",
            "Epoch [21], val_loss: 0.3562, val_acc: 0.9028\n",
            "Epoch [22], val_loss: 0.3559, val_acc: 0.9029\n",
            "Epoch [23], val_loss: 0.3557, val_acc: 0.9029\n",
            "Epoch [24], val_loss: 0.3555, val_acc: 0.9029\n",
            "Epoch [25], val_loss: 0.3552, val_acc: 0.9031\n",
            "Epoch [26], val_loss: 0.3550, val_acc: 0.9032\n",
            "Epoch [27], val_loss: 0.3548, val_acc: 0.9032\n",
            "Epoch [28], val_loss: 0.3546, val_acc: 0.9032\n",
            "Epoch [29], val_loss: 0.3543, val_acc: 0.9032\n",
            "Epoch [30], val_loss: 0.3541, val_acc: 0.9032\n",
            "Epoch [31], val_loss: 0.3539, val_acc: 0.9033\n",
            "Epoch [32], val_loss: 0.3536, val_acc: 0.9033\n",
            "Epoch [33], val_loss: 0.3534, val_acc: 0.9033\n",
            "Epoch [34], val_loss: 0.3532, val_acc: 0.9033\n",
            "Epoch [35], val_loss: 0.3530, val_acc: 0.9033\n",
            "Epoch [36], val_loss: 0.3528, val_acc: 0.9033\n",
            "Epoch [37], val_loss: 0.3526, val_acc: 0.9034\n",
            "Epoch [38], val_loss: 0.3524, val_acc: 0.9033\n",
            "Epoch [39], val_loss: 0.3522, val_acc: 0.9033\n",
            "Epoch [40], val_loss: 0.3520, val_acc: 0.9033\n",
            "Epoch [41], val_loss: 0.3517, val_acc: 0.9034\n",
            "Epoch [42], val_loss: 0.3515, val_acc: 0.9034\n",
            "Epoch [43], val_loss: 0.3513, val_acc: 0.9032\n",
            "Epoch [44], val_loss: 0.3511, val_acc: 0.9033\n",
            "Epoch [45], val_loss: 0.3509, val_acc: 0.9034\n",
            "Epoch [46], val_loss: 0.3507, val_acc: 0.9033\n",
            "Epoch [47], val_loss: 0.3505, val_acc: 0.9034\n",
            "Epoch [48], val_loss: 0.3503, val_acc: 0.9033\n",
            "Epoch [49], val_loss: 0.3501, val_acc: 0.9036\n",
            "Epoch [50], val_loss: 0.3499, val_acc: 0.9034\n",
            "Epoch [51], val_loss: 0.3497, val_acc: 0.9035\n",
            "Epoch [52], val_loss: 0.3495, val_acc: 0.9034\n",
            "Epoch [53], val_loss: 0.3493, val_acc: 0.9034\n",
            "Epoch [54], val_loss: 0.3492, val_acc: 0.9037\n",
            "Epoch [55], val_loss: 0.3489, val_acc: 0.9039\n",
            "Epoch [56], val_loss: 0.3488, val_acc: 0.9037\n",
            "Epoch [57], val_loss: 0.3486, val_acc: 0.9037\n",
            "Epoch [58], val_loss: 0.3484, val_acc: 0.9038\n",
            "Epoch [59], val_loss: 0.3482, val_acc: 0.9039\n",
            "Epoch [60], val_loss: 0.3480, val_acc: 0.9039\n",
            "Epoch [61], val_loss: 0.3478, val_acc: 0.9040\n",
            "Epoch [62], val_loss: 0.3476, val_acc: 0.9039\n",
            "Epoch [63], val_loss: 0.3475, val_acc: 0.9040\n",
            "Epoch [64], val_loss: 0.3473, val_acc: 0.9040\n",
            "Epoch [65], val_loss: 0.3471, val_acc: 0.9041\n",
            "Epoch [66], val_loss: 0.3469, val_acc: 0.9041\n",
            "Epoch [67], val_loss: 0.3467, val_acc: 0.9041\n",
            "Epoch [68], val_loss: 0.3465, val_acc: 0.9042\n",
            "Epoch [69], val_loss: 0.3464, val_acc: 0.9044\n",
            "Epoch [70], val_loss: 0.3462, val_acc: 0.9044\n",
            "Epoch [71], val_loss: 0.3460, val_acc: 0.9044\n",
            "Epoch [72], val_loss: 0.3458, val_acc: 0.9044\n",
            "Epoch [73], val_loss: 0.3457, val_acc: 0.9044\n",
            "Epoch [74], val_loss: 0.3455, val_acc: 0.9045\n",
            "Epoch [75], val_loss: 0.3453, val_acc: 0.9046\n",
            "Epoch [76], val_loss: 0.3451, val_acc: 0.9047\n",
            "Epoch [77], val_loss: 0.3450, val_acc: 0.9046\n",
            "Epoch [78], val_loss: 0.3448, val_acc: 0.9047\n",
            "Epoch [79], val_loss: 0.3446, val_acc: 0.9048\n",
            "Epoch [80], val_loss: 0.3445, val_acc: 0.9048\n",
            "Epoch [81], val_loss: 0.3443, val_acc: 0.9047\n",
            "Epoch [82], val_loss: 0.3441, val_acc: 0.9047\n",
            "Epoch [83], val_loss: 0.3440, val_acc: 0.9047\n",
            "Epoch [84], val_loss: 0.3438, val_acc: 0.9045\n",
            "Epoch [85], val_loss: 0.3436, val_acc: 0.9048\n",
            "Epoch [86], val_loss: 0.3435, val_acc: 0.9049\n",
            "Epoch [87], val_loss: 0.3433, val_acc: 0.9048\n",
            "Epoch [88], val_loss: 0.3432, val_acc: 0.9048\n",
            "Epoch [89], val_loss: 0.3430, val_acc: 0.9048\n",
            "Epoch [90], val_loss: 0.3429, val_acc: 0.9048\n",
            "Epoch [91], val_loss: 0.3427, val_acc: 0.9049\n",
            "Epoch [92], val_loss: 0.3425, val_acc: 0.9050\n",
            "Epoch [93], val_loss: 0.3424, val_acc: 0.9051\n",
            "Epoch [94], val_loss: 0.3422, val_acc: 0.9052\n",
            "Epoch [95], val_loss: 0.3421, val_acc: 0.9054\n",
            "Epoch [96], val_loss: 0.3419, val_acc: 0.9054\n",
            "Epoch [97], val_loss: 0.3417, val_acc: 0.9054\n",
            "Epoch [98], val_loss: 0.3416, val_acc: 0.9054\n",
            "Epoch [99], val_loss: 0.3414, val_acc: 0.9055\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TUJmWQbB2opB"
      },
      "source": [
        "# Define test dataset\n",
        "test_dataset = MNIST(root='data/', \n",
        "                     train=False,\n",
        "                     transform=transforms.ToTensor())"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvou7wj12wAI"
      },
      "source": [
        "def predict_image(img, model):\n",
        "    xb = img.unsqueeze(0)\n",
        "    yb = model(xb)\n",
        "    _, preds = torch.max(yb, dim=1)\n",
        "    return preds[0].item()"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "sa72AzVo22_-",
        "outputId": "f312d242-8066-4e74-ed71-570c3a301a65"
      },
      "source": [
        "img, label = test_dataset[10]\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "print('Label:', label, ', Predicted:', predict_image(img, model))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 0 , Predicted: 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "naM0JXrE26hF",
        "outputId": "494d583b-35de-419e-eb51-a5cf197a0dd8"
      },
      "source": [
        "img, label = test_dataset[1839]\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "print('Label:', label, ', Predicted:', predict_image(img, model))"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 2 , Predicted: 8\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "a1m-upEf27T1",
        "outputId": "918c42c3-c4bb-4849-a7f0-3e7d27064d63"
      },
      "source": [
        "img, label = test_dataset[0]\n",
        "plt.imshow(img[0], cmap='gray')\n",
        "print('Label:', label, ', Predicted:', predict_image(img, model))"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label: 7 , Predicted: 7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZhPgdSYY3Rko",
        "outputId": "952d94cd-50a3-438d-9e64-0f59274664ba"
      },
      "source": [
        "test_loader = DataLoader(test_dataset, batch_size=256)\n",
        "result = evaluate(model, test_loader)\n",
        "result"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'val_acc': 0.9131835699081421, 'val_loss': 0.3187054991722107}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    }
  ]
}